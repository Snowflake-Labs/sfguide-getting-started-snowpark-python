{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40e74aaa",
   "metadata": {},
   "source": [
    "# Customer churn analysis\n",
    "\n",
    "## Exploratory data analysis (EDA)\n",
    "\n",
    "This demo is continuation of the telco pipeline after data load, clean and transformation. We will now try to explore data using snowpark and other python library. This task help us identify further transformations, importatn variable discovery and any feature engineering thats required later.\n",
    "\n",
    "## Analysis\n",
    "\n",
    "**We will analyse the following:**\n",
    "\n",
    "1. The target variable\n",
    "2. Variable types (categorical and numerical)\n",
    "3. Missing data\n",
    "4. Numerical variables\n",
    "    - Discrete\n",
    "    - Continuous\n",
    "    - Distributions\n",
    "    - Transformations\n",
    "\n",
    "5. Categorical variables\n",
    "    - Cardinality\n",
    "    - Rare Labels\n",
    "    - Special mappings\n",
    "\n",
    "\n",
    "<img src=\"arch.jpg\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b06da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark import functions as F\n",
    "from snowflake.snowpark.types import *\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "#Snowflake connection info\n",
    "from config import snowflake_conn_prop\n",
    "\n",
    "\n",
    "# lets import some tranformations functions\n",
    "from snowflake.snowpark.functions import udf, col, lit, translate, is_null, iff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24477372",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import version\n",
    "print(version.VERSION)\n",
    "\n",
    "session = Session.builder.configs(snowflake_conn_prop).create()\n",
    "print(session.sql('select current_warehouse(), current_database(), current_schema()').collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e619437",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "raw = session.table('TRAIN_DATASET').sample(n = 20000)\n",
    "data = raw.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de36cb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to display all the columns of the dataframe in the notebook\n",
    "pd.pandas.set_option('display.max_columns', None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d34b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13b4add",
   "metadata": {},
   "source": [
    "## Check Target Distribution\n",
    "\n",
    "Let's begin by exploring the target distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca56e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll print the target variable, target names, and frequency of each unique value:\n",
    "\n",
    "(unique, counts) = np.unique(data['CHURNVALUE'], return_counts=True)\n",
    "\n",
    "print('Unique values of target variable', unique)\n",
    "print('Counts of target variable', counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e172f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=unique, y=counts)\n",
    "plt.title('Target variable counts in dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6840e12e",
   "metadata": {},
   "source": [
    "## Step 1: Define explonatory variables and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cf5233",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670cbfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's identify the categorical variables\n",
    "# we will capture those of type *object* and boolean\n",
    "cat_vars = [var for var in data.columns if ((data[var].dtype == 'O') or (data[var].dtype==\"bool\"))]\n",
    "\n",
    "# Remove misinterpreted objects like \"CustomerID\"\n",
    "cat_vars.pop(0)\n",
    "\n",
    "print(cat_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c22dc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's identify the numerical variables\n",
    "num_vars = [var for var in data.columns if var not in cat_vars and var != 'CHURNVALUE' and var != 'CUSTOMERID']\n",
    "\n",
    "# number of numerical variables\n",
    "print(num_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee8ea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot histograms for all continuous variables\n",
    "print(data[num_vars].head())\n",
    "data[num_vars].hist(bins=30, figsize=(15,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87323bf5",
   "metadata": {},
   "source": [
    "# Missing values\n",
    "\n",
    "Let's go ahead and find out which variables of the dataset contain missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5285a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of the variables that contain missing values\n",
    "vars_with_na = [var for var in data.columns if data[var].isnull().sum() > 0]\n",
    "\n",
    "# determine percentage of missing values (expressed as decimals)\n",
    "# and display the result ordered by % of missin data\n",
    "\n",
    "data[vars_with_na].isnull().mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbb4d21",
   "metadata": {},
   "source": [
    "# Numerical variables\n",
    "\n",
    "Let's go ahead and find out what numerical variables we have in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a228cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of numerical variables: ', len(num_vars))\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "num_df = data[num_vars]\n",
    "scaler.fit(num_df,y=None)\n",
    "\n",
    "# visualise the numerical variables\n",
    "num_df.head()\n",
    "# Before Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62078e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets plot histograms for all continuous variables\n",
    "new_df = pd.DataFrame(scaler.transform(num_df),columns=data[num_vars].columns)\n",
    "\n",
    "#new_df2 = pd.DataFrame(np.log(new_df),columns=data[num_vars].columns)\n",
    "new_df.head()\n",
    "#new_df.hist(bins=50, figsize=(20,20))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3214ac97",
   "metadata": {},
   "source": [
    "## Taking care of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d20ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_outliers(df,out_name):\n",
    "    iqr = 1.5 * (np.percentile(df[out_name], 75) - np.percentile(df[out_name], 25))\n",
    "    df.drop(df[df[out_name] > (iqr + np.percentile(df[out_name], 75))].index, inplace=True)\n",
    "    df.drop(df[df[out_name] < (np.percentile(df[out_name], 25) - iqr)].index, inplace=True)\n",
    "    \n",
    "\n",
    "drop_outliers(data,'TENUREMONTHS')\n",
    "drop_outliers(data,'MONTHLYCHARGES')\n",
    "drop_outliers(data,'TOTALCHARGES')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6b65f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=data['MONTHLYCHARGES'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db419f61",
   "metadata": {},
   "source": [
    "# Categorical variables\n",
    "\n",
    "Let's go ahead and analyse the categorical variables present in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ad3850",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of categorical variables: ', len(cat_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f9776c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's visualise the values of the categorical variables\n",
    "data[cat_vars].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e123f099",
   "metadata": {},
   "source": [
    "## Number of labels: cardinality\n",
    "\n",
    "Let's evaluate how many different categories are present in each of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f066140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we count unique categories with pandas unique() \n",
    "# and then plot them in descending order\n",
    "\n",
    "data[cat_vars].nunique().sort_values(ascending=False).plot.bar(figsize=(12,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca991cbf",
   "metadata": {},
   "source": [
    "## Rare labels:\n",
    "\n",
    "Let's go ahead and investigate now if there are labels that are present only in a small number of customers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c0e442",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cat_vars)\n",
    "def analyse_rare_labels(df, var, rare_perc):\n",
    "    df = df.copy()\n",
    "\n",
    "    # determine the % of observations per category\n",
    "    tmp = df.groupby(var)['CHURNVALUE'].count() / len(df)\n",
    "\n",
    "    # return categories that are rare\n",
    "    return tmp[tmp < rare_perc]\n",
    "\n",
    "# print categories that are present in less than\n",
    "# 1 % of the observations\n",
    "\n",
    "for var in cat_vars:\n",
    "    print(analyse_rare_labels(data, var, 0.01))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffebb933",
   "metadata": {},
   "source": [
    "### So all the cat variables are distributed well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b07c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[cat_vars].shape, data[num_vars].shape, data['CHURNVALUE'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d910d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final columns that we want in our training data set are cat, num and target variables\n",
    "final_cols = cat_vars + num_vars + ['CHURNVALUE']\n",
    "final_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3ce0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "snowpark_train_df = session.write_pandas(data[final_cols], 'TELCO_TRAIN_SET', auto_create_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d631845",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowpark_train_df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bb54b7",
   "metadata": {},
   "source": [
    "# Off to training a model and deplyment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c180046a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pysnowpark5",
   "language": "python",
   "name": "pysnowpark5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
